{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Post(object):\n",
      "    def __init__(self, url, price=None):\n",
      "        self.url = url\n",
      "        self.price = price\n",
      "        self.postsoup = None\n",
      "        \n",
      "    @classmethod\n",
      "    def find_price(cls, post):\n",
      "        results = post.find('span', attrs={'class':'price'})\n",
      "        if results is None: \n",
      "            return results\n",
      "        return results.contents[0].replace('$','')\n",
      "    \n",
      "    def parse_post_metadata(self):\n",
      "        # Only do if soup doesn't already exist.\n",
      "        if self.postsoup is None:\n",
      "            self.get_post_soup()\n",
      "        self.title = self.postsoup.title.text\n",
      "        self.anon_email = self.get_anon_email()\n",
      "        self.user_email = self.get_user_email()\n",
      "        self.posted_time = self.get_posted_time()\n",
      "        self.updated_time = self.get_updated_time()\n",
      "        self.postid = re.search('/(\\d+).htm', self.url).groups()[0]\n",
      "        self.text = self.postsoup.find('section', id='postingbody').text.strip()\n",
      "        \n",
      "    def get_post_soup(self):\n",
      "        \"\"\"Load the soup for the page of the posting if not already loaded.\n",
      "        \"\"\"\n",
      "        r = requests.get(self.url)\n",
      "        self.postsoup = BeautifulSoup(r.text) \n",
      "    \n",
      "    def get_anon_email(self):\n",
      "        \"\"\"Grab the anonomized email address from the link provided on the posting page\"\"\"\n",
      "        try:\n",
      "            return parse_anonemail(self.postsoup)\n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "    def get_user_email(self):\n",
      "        \"\"\"Grab any emails the poster provided in the text of the page\"\"\"\n",
      "        try:\n",
      "            return parse_useremail(self.postsoup) \n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "    def get_posted_time(self):\n",
      "        try:\n",
      "            for pclass in self.postsoup.find_all('p', class_='postinginfo'):\n",
      "                if 'Posted:' in pclass.text:\n",
      "                    return pclass.time['datetime']\n",
      "            return None\n",
      "        except:\n",
      "            return None\n",
      "            \n",
      "    def get_updated_time(self):\n",
      "        try:\n",
      "            for pclass in self.postsoup.find_all('p', class_='postinginfo'):\n",
      "                if 'updated:' in pclass.text:\n",
      "                    return pclass.time['datetime']\n",
      "            return None\n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "def parse_anonemail(soup):\n",
      "    for link in soup.find_all('a'):\n",
      "        match = re.search('([a-zA-Z0-9._%+-]+@\\w+\\.craigslist\\.[\\w]{2,4})', link.get('href'))\n",
      "        if match is not None:\n",
      "            return match.group(1)\n",
      "    return None\n",
      "\n",
      "def parse_useremail(soup):\n",
      "    re.search('([a-zA-Z0-9._%+-]+@[a-zA-z0-9.-]+\\.[\\w]{2,4})', soup.get_text())   \n",
      "    \n",
      "def get_city(soup):\n",
      "    \"\"\"Using the breadcrumbs at the top of all craigslist pages, figure out what city you're in.\n",
      "    \"\"\"\n",
      "    return soup.find_all('span', class_='crumb')[1].a.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Search(object):\n",
      "    def __init__(self, ccity, ccategory, query=None, csearchtype='A', chood=None, minask=None, maxask=None, haspic=False):\n",
      "        self.ccity = ccity\n",
      "        self.ccategory = ccategory\n",
      "        self.query = query\n",
      "        self.csearchtype = csearchtype #possibilities: A=all, T=title\n",
      "        self.chood = chood\n",
      "        self.minask = minask\n",
      "        self.maxask = maxask\n",
      "        self.haspic = haspic\n",
      "        \n",
      "        self.cminask = '' if minask is None else str(minask)\n",
      "        self.cmaxask = '' if maxask is None else str(maxask)\n",
      "        self.chaspic = '1' if haspic else '0'\n",
      "        \n",
      "    def format_search_url(self):\n",
      "        #http://seattle.craigslist.org/search/sya/est?query=lenovo&zoomToPosting=&srchType=T&minAsk=10&maxAsk=10000&hasPic=1\n",
      "        if self.query == None:\n",
      "            return 'http://{0}.craigslist.org/{1}{2}'.format(self.ccity, postslash(self.chood), self.ccategory)\n",
      "        return 'http://{0}.craigslist.org/search/{1}{7}?query={2}&srchType={3}&minAsk={4}&maxAsk={5}&hasPic={6}'.format(\n",
      "                    self.ccity, self.ccategory, self.query, self.csearchtype, self.cminask, self.cmaxask, \n",
      "                    self.chaspic, preslash(self.chood))\n",
      "    \n",
      "    def find_postings(self):\n",
      "        pass\n",
      "    \n",
      "        \n",
      "postslash = lambda x: '' if x is None else x+'/'\n",
      "preslash = lambda x: '' if x is None else '/'+x\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ms = Search('seattle', 'mcy', query='sport', chood='see', csearchtype='A', minask=1, maxask='10000')\n",
      "site = ms.format_search_url()\n",
      "print site\n",
      "r = requests.get(site)\n",
      "soup = BeautifulSoup(r.text)   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://seattle.craigslist.org/search/mcy/see?query=sport&srchType=A&minAsk=1&maxAsk=10000&hasPic=0\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = \"http://seattle.craigslist.org/search/fua/see?zoomToPosting=&catAbb=fua&query=bed+frame&minAsk=&maxAsk=&excats=\"\n",
      "re.search('.craigslist.org"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "postings = soup('p')\n",
      "\n",
      "for bs4tag in postings[:10]:  \n",
      "    post_href = bs4tag('a')[1].get('href')[1:]\n",
      "    post = Post('http://%s.craigslist.org/'%ms.ccity + post_href, Post.find_price(bs4tag))\n",
      "    post.parse_post_metadata()\n",
      "    print post.title\n",
      "    print '$', post.price\n",
      "    print post.posted_time\n",
      "    print post.updated_time\n",
      "    print post.postid\n",
      "    print post.user_email\n",
      "    print post.url\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2003 Triumph Tiger 955i\n",
        "$ 3000\n",
        "2014-04-17T13:04:15-0700\n",
        "None\n",
        "4427694433\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4427694433.html\n",
        "\n",
        "1995 BMW R100GSPD Classic Edition"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 7000\n",
        "2014-04-17T12:10:24-0700\n",
        "None\n",
        "4427600538\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4427600538.html\n",
        "\n",
        "2010 KTM 450 XCW -- street legal"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 6250\n",
        "2014-04-17T11:26:57-0700\n",
        "None\n",
        "4427522498\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4427522498.html\n",
        "\n",
        "2007 Suzuki boulevard M109R****"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 9000\n",
        "2014-04-17T10:32:21-0700\n",
        "None\n",
        "4427421981\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4427421981.html\n",
        "\n",
        "1970 Honda Trail 90 CT90 CT-90, hi-lo transmission, folding bars, runs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 550\n",
        "2014-04-17T09:05:57-0700\n",
        "None\n",
        "4427261578\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4427261578.html\n",
        "\n",
        "2005 Honda CRF450r"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 2900\n",
        "2014-04-17T07:34:47-0700\n",
        "None\n",
        "4427104438\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4427104438.html\n",
        "\n",
        "BMW R1100GS for sale"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 4850\n",
        "2014-04-16T22:49:55-0700\n",
        "None\n",
        "4426805199\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4426805199.html\n",
        "\n",
        "2008 gsxr 1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 6000\n",
        "2014-04-16T22:17:34-0700\n",
        "None\n",
        "4426788778\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4426788778.html\n",
        "\n",
        "CBR 1000rr race/track/street $4500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 4500\n",
        "2014-04-16T21:22:15-0700\n",
        "None\n",
        "4426753450\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4426753450.html\n",
        "\n",
        "CBR 1000rr race/track/street $4500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "$ 4500\n",
        "2014-04-16T21:20:31-0700\n",
        "None\n",
        "4426752200\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4426752200.html\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scratch"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}