{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Post(object):\n",
      "    def __init__(self, url):\n",
      "        self.url = url\n",
      "        self.postsoup = None\n",
      "        \n",
      "    @classmethod\n",
      "    def find_price(cls, post):\n",
      "        results = post.find('span', attrs={'class':'price'})\n",
      "        if results is None: \n",
      "            return results\n",
      "        return results.contents[0].replace('$','')\n",
      "    \n",
      "    def parse_post_metadata(self):\n",
      "        # Only do if soup doesn't already exist.\n",
      "        if self.postsoup is None:\n",
      "            self.get_post_soup()\n",
      "        self.title = self.postsoup.title.text\n",
      "        self.anon_email = self.get_anon_email()\n",
      "        self.user_email = self.get_user_email()\n",
      "        self.posted_time = self.get_posted_time()\n",
      "        self.updated_time = self.get_updated_time()\n",
      "        self.postid = re.search('/(\\d+).htm', self.url).groups()[0]\n",
      "        self.text = self.postsoup.find('section', id='postingbody').text.strip()\n",
      "        self.price = self.get_price()\n",
      "        \n",
      "    def get_post_soup(self):\n",
      "        \"\"\"Load the soup for the page of the posting if not already loaded.\n",
      "        \"\"\"\n",
      "        r = requests.get(self.url)\n",
      "        self.postsoup = BeautifulSoup(r.text) \n",
      "    \n",
      "    def get_anon_email(self):\n",
      "        \"\"\"Grab the anonomized email address from the link provided on the posting page\"\"\"\n",
      "        try:\n",
      "            return parse_anonemail(self.postsoup)\n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "    def get_user_email(self):\n",
      "        \"\"\"Grab any emails the poster provided in the text of the page\"\"\"\n",
      "        try:\n",
      "            return parse_useremail(self.postsoup) \n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "    def get_price(self):\n",
      "        \"\"\"Get the price listed in the h2 page element (seems to always be present)\"\"\"\n",
      "        try:\n",
      "            post_header2 = self.postsoup.find_all('h2', class_='postingtitle')[0].text.strip()\n",
      "            return int(re.findall(' - \\$(\\d+) \\(', post_header2)[0]) #looks for a number in the pattern [- $xxx (]\n",
      "        except:\n",
      "            return None\n",
      "    \n",
      "    def get_posted_time(self):\n",
      "        try:\n",
      "            for pclass in self.postsoup.find_all('p', class_='postinginfo'):\n",
      "                if 'Posted:' in pclass.text:\n",
      "                    return pclass.time['datetime']\n",
      "            return None\n",
      "        except:\n",
      "            return None\n",
      "            \n",
      "    def get_updated_time(self):\n",
      "        try:\n",
      "            for pclass in self.postsoup.find_all('p', class_='postinginfo'):\n",
      "                if 'updated:' in pclass.text:\n",
      "                    return pclass.time['datetime']\n",
      "            return None\n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "def parse_anonemail(soup):\n",
      "    for link in soup.find_all('a'):\n",
      "        match = re.search('([a-zA-Z0-9._%+-]+@\\w+\\.craigslist\\.[\\w]{2,4})', link.get('href'))\n",
      "        if match is not None:\n",
      "            return match.group(1)\n",
      "    return None\n",
      "\n",
      "def parse_useremail(soup):\n",
      "    return re.search('([a-zA-Z0-9._%+-]+@[a-zA-z0-9.-]+\\.[\\w]{2,4})', soup.get_text())   \n",
      "    \n",
      "def get_city(soup):\n",
      "    \"\"\"Using the breadcrumbs at the top of all craigslist pages, figure out what city you're in.\n",
      "    \"\"\"\n",
      "    return soup.find_all('span', class_='crumb')[1].a.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class SearchURL(object):\n",
      "   def __init__(self, url=None, ccity=None, ccategory=None, query=None, csearchtype='A', \n",
      "             chood=None, minask=None, maxask=None, haspic=False):\n",
      "    self.url = url\n",
      "    self.ccity = ccity\n",
      "    self.ccategory = ccategory\n",
      "    self.query = query\n",
      "    self.csearchtype = csearchtype #possibilities: A=all, T=title\n",
      "    self.chood = chood\n",
      "    self.minask = minask\n",
      "    self.maxask = maxask\n",
      "    self.haspic = haspic\n",
      "    \n",
      "    self.cminask = '' if minask is None else str(minask)\n",
      "    self.cmaxask = '' if maxask is None else str(maxask)\n",
      "    self.chaspic = '1' if haspic else '0'\n",
      "    \n",
      "    if url is None:\n",
      "        try:\n",
      "            self.url = self.format_search_url()\n",
      "        except:\n",
      "            pass\n",
      "            \n",
      "    def format_search_url(self):\n",
      "        #http://seattle.craigslist.org/search/sya/est?query=lenovo&zoomToPosting=&srchType=T&minAsk=10&maxAsk=10000&hasPic=1\n",
      "        if self.query == None:\n",
      "            return 'http://{0}.craigslist.org/{1}{2}'.format(self.ccity, postslash(self.chood), self.ccategory)\n",
      "        return 'http://{0}.craigslist.org/search/{1}{7}?query={2}&srchType={3}&minAsk={4}&maxAsk={5}&hasPic={6}'.format(\n",
      "                    self.ccity, self.ccategory, self.query, self.csearchtype, self.cminask, self.cmaxask, \n",
      "                    self.chaspic, preslash(self.chood)) \n",
      "\n",
      "class Search(object):\n",
      "    def __init__(self, url):\n",
      "        self.url = url\n",
      "        self.city = re.findall('[/.](\\w+).craigslist.org', self.url)[0]\n",
      "    \n",
      "    def search_postings(self):\n",
      "        posts = []\n",
      "        r = requests.get(self.url)\n",
      "        soup = BeautifulSoup(r.text)\n",
      "        post_paragraphs = soup('p')\n",
      "        for post_soup in post_paragraphs:\n",
      "            post_href = post_soup('a')[1].get('href')[1:]\n",
      "            post = Post('http://%s.craigslist.org/'%self.city + post_href)\n",
      "            posts.append(post)\n",
      "            \n",
      "        return posts\n",
      "    \n",
      "        \n",
      "postslash = lambda x: '' if x is None else x+'/'\n",
      "preslash = lambda x: '' if x is None else '/'+x\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bedsearch = Search(\"http://seattle.craigslist.org/search/fua/see?zoomToPosting=&catAbb=fua&query=bed+frame&minAsk=&maxAsk=&excats=\")\n",
      "posts = bedsearch.search_postings()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for post in posts[:5]:\n",
      "    print post.url\n",
      "    post.parse_post_metadata()\n",
      "    print post.title\n",
      "    print post.price\n",
      "    print post.anon_email\n",
      "    print post.user_email"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://seattle.craigslist.org/see/fuo/4429339049.html\n",
        "Leggett & Platt Twin bed frame\n",
        "40\n",
        "None\n",
        "None\n",
        "http://seattle.craigslist.org/see/fuo/4429337652.html\n",
        "Queen size sleigh bed frame\n",
        "200\n",
        "None\n",
        "None\n",
        "http://seattle.craigslist.org/see/fuo/4421413325.html\n",
        "MID Century DANISH Modern SOLID TEAK Floating NIGHTSTAND Queen BEDRAME\n",
        "450\n",
        "None\n",
        "None\n",
        "http://seattle.craigslist.org/see/fuo/4429295732.html\n",
        "Full size four poster bed frame Nice!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "150\n",
        "None\n",
        "None\n",
        "http://seattle.craigslist.org/see/fuo/4421623145.html\n",
        "full bed frame $60\n",
        "60\n",
        "None\n",
        "None\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scratch"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "post = Post('http://seattle.craigslist.org/see/mcy/4427694433.html')\n",
      "post.parse_post_metadata()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "post.postsoup.find_all('a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "[<a href=\"https://post.craigslist.org/c/sea?lang=en\">post</a>,\n",
        " <a href=\"https://accounts.craigslist.org\">account</a>,\n",
        " <a class=\"favlink\" href=\"#\"><span class=\"n\">0</span> favorites</a>,\n",
        " <a href=\"//www.craigslist.org/about/sites\">CL</a>,\n",
        " <a href=\"http://seattle.craigslist.org/\">seattle</a>,\n",
        " <a href=\"http://seattle.craigslist.org/see/\">seattle</a>,\n",
        " <a href=\"http://seattle.craigslist.org/see/sss/\">all for sale / wanted</a>,\n",
        " <a href=\"http://seattle.craigslist.org/see/mcy/\">motorcycles/scooters - by owner</a>,\n",
        " <a href=\"/reply/4427694433\">contact</a>,\n",
        " <a class=\"flaglink\" data-flag=\"28\" href=\"https://post.craigslist.org/flag?flagCode=28&amp;postingID=4427694433&amp;subareaid=1&amp;areaid=2&amp;cat=mcy&amp;area=sea\" title=\"flag as prohibited / spam / miscategorized\"><span class=\"flag\">x</span> <span class=\"flagtext\">prohibited</span></a>,\n",
        " <a href=\"http://www.craigslist.org/about/prohibited\">?</a>,\n",
        " <a href=\"http://images.craigslist.org/00G0G_2kHqEgGi4fw_600x450.jpg\" title=\"1\"><img alt=\"image 1\" class=\"selected\" src=\"http://images.craigslist.org/00G0G_2kHqEgGi4fw_50x50c.jpg\"/></a>,\n",
        " <a href=\"http://images.craigslist.org/00D0D_c04AVtvB12G_600x450.jpg\" title=\"2\"><img alt=\"image 2\" src=\"http://images.craigslist.org/00D0D_c04AVtvB12G_50x50c.jpg\"/></a>,\n",
        " <a href=\"http://images.craigslist.org/00B0B_38OAMnEs6BZ_600x450.jpg\" title=\"3\"><img alt=\"image 3\" src=\"http://images.craigslist.org/00B0B_38OAMnEs6BZ_50x50c.jpg\"/></a>,\n",
        " <a href=\"https://maps.google.com/?q=loc%3A+%36%32%35+Wellington+Ave+Walla+Walla+Wa+US\" target=\"_blank\">google map</a>,\n",
        " <a href=\"http://maps.yahoo.com/maps_result?addr=%36%32%35+Wellington+Ave&amp;csz=Walla+Walla+Wa&amp;country=US\" target=\"_blank\">yahoo map</a>,\n",
        " <a class=\"tsb\" href=\"https://accounts.craigslist.org/eaf?postingID=4427694433&amp;token=U2FsdGVkX181NTE3NTUxN2OwaCEa1nCn56IScecxHD0CJ-0VB9etZmtppplRgyZ8Csd-3e7hXwI62J6b6CrhaQKB-c2AZT9W\">email to friend</a>,\n",
        " <a class=\"bestoflink\" data-flag=\"9\" href=\"https://post.craigslist.org/flag?flagCode=9&amp;postingID=4427694433&amp;\" title=\"nominate for best-of-CL\"><span class=\"bestof\">\u2665 </span><span class=\"bestoftext\">best of</span></a>,\n",
        " <a href=\"http://www.craigslist.org/about/best-of-craigslist\">?</a>,\n",
        " <a href=\"//www.craigslist.org/about/scams\">Avoid scams, deal locally</a>,\n",
        " <a href=\"//www.craigslist.org/about/help/\">help</a>,\n",
        " <a href=\"//www.craigslist.org/about/scams\">safety</a>,\n",
        " <a href=\"//www.craigslist.org/about/privacy.policy\">privacy</a>,\n",
        " <a href=\"https://forums.craigslist.org/?forumID=8\">feedback</a>,\n",
        " <a href=\"//www.craigslist.org/about/craigslist_is_hiring\">cl jobs</a>,\n",
        " <a href=\"//www.craigslist.org/about/terms.of.use\">terms</a>,\n",
        " <a href=\"//www.craigslist.org/about/\">about</a>,\n",
        " <a href=\"#\">mobile</a>,\n",
        " <a href=\"#\">desktop</a>]"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}