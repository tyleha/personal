{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Post(object):\n",
      "    def __init__(self, url, price=None):\n",
      "        self.url = url\n",
      "        self.price = price\n",
      "        self.postsoup = None\n",
      "        \n",
      "    @classmethod\n",
      "    def find_price(cls, post):\n",
      "        results = post.find('span', attrs={'class':'price'})\n",
      "        if results is None: \n",
      "            return results\n",
      "        return results.contents[0].replace('$','')\n",
      "    \n",
      "    def parse_post_metadata(self):\n",
      "        self.get_post_soup()\n",
      "        self.title = self.postsoup.title.text\n",
      "        self.anon_email = self.get_anon_email()\n",
      "        self.user_email = self.get_user_email()\n",
      "        self.posted_time = self.get_posted_time()\n",
      "        self.updated_time = self.get_updated_time()\n",
      "        self.postid = re.search('/(\\d+).htm', self.url).groups()[0]\n",
      "        self.text = self.postsoup.find('section', id='postingbody').text.strip()\n",
      "        \n",
      "    def get_post_soup(self):\n",
      "        \"\"\"Load the soup for the page of the posting if not already loaded.\n",
      "        \"\"\"\n",
      "        # Only do if soup doesn't already exist.\n",
      "        if self.postsoup is None:\n",
      "            r = requests.get(self.url)\n",
      "            self.postsoup = BeautifulSoup(r.text) \n",
      "    \n",
      "    def get_anon_email(self):\n",
      "        \"\"\"Grab the anonomized email address from the link provided on the posting page\"\"\"\n",
      "        try:\n",
      "            return parse_anonemail(self.postsoup)\n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "    def get_user_email(self):\n",
      "        \"\"\"Grab any emails the poster provided in the text of the page\"\"\"\n",
      "        try:\n",
      "            return parse_useremail(self.postsoup) \n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "    def get_posted_time(self):\n",
      "        try:\n",
      "            for pclass in self.postsoup.find_all('p', class_='postinginfo'):\n",
      "                if 'Posted:' in pclass.text:\n",
      "                    return pclass.time['datetime']\n",
      "            return None\n",
      "        except:\n",
      "            return None\n",
      "            \n",
      "    def get_updated_time(self):\n",
      "        try:\n",
      "            for pclass in self.postsoup.find_all('p', class_='postinginfo'):\n",
      "                if 'updated:' in pclass.text:\n",
      "                    return pclass.time['datetime']\n",
      "            return None\n",
      "        except:\n",
      "            return None\n",
      "        \n",
      "def parse_anonemail(soup):\n",
      "    for link in soup.find_all('a'):\n",
      "        match = re.search('([a-zA-Z0-9._%+-]+@\\w+\\.craigslist\\.[\\w]{2,4})', link.get('href'))\n",
      "        if match is not None:\n",
      "            return match.group(1)\n",
      "    return None\n",
      "\n",
      "def parse_useremail(soup):\n",
      "    re.search('([a-zA-Z0-9._%+-]+@[a-zA-z0-9.-]+\\.[\\w]{2,4})', soup.get_text())   \n",
      "    \n",
      "def get_city(soup):\n",
      "    \"\"\"Using the breadcrumbs at the top of all craigslist pages, figure out what city you're in.\n",
      "    \"\"\"\n",
      "    return soup.find_all('span', class_='crumb')[1].a.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Search(object):\n",
      "    def __init__(self, ccity, ccategory, query=None, csearchtype='A', chood=None, minask=None, maxask=None, haspic=False):\n",
      "        self.ccity = ccity\n",
      "        self.ccategory = ccategory\n",
      "        self.query = query\n",
      "        self.csearchtype = csearchtype #possibilities: A=all, T=title\n",
      "        self.chood = chood\n",
      "        self.minask = minask\n",
      "        self.maxask = maxask\n",
      "        self.haspic = haspic\n",
      "        \n",
      "        self.cminask = '' if minask is None else str(minask)\n",
      "        self.cmaxask = '' if maxask is None else str(maxask)\n",
      "        self.chaspic = '1' if haspic else '0'\n",
      "        \n",
      "    def format_search_url(self):\n",
      "        #http://seattle.craigslist.org/search/sya/est?query=lenovo&zoomToPosting=&srchType=T&minAsk=10&maxAsk=10000&hasPic=1\n",
      "        if self.query == None:\n",
      "            return 'http://{0}.craigslist.org/{1}{2}'.format(self.ccity, postslash(self.chood), self.ccategory)\n",
      "        return 'http://{0}.craigslist.org/search/{1}{7}?query={2}&srchType={3}&minAsk={4}&maxAsk={5}&hasPic={6}'.format(\n",
      "                    self.ccity, self.ccategory, self.query, self.csearchtype, self.cminask, self.cmaxask, \n",
      "                    self.chaspic, preslash(self.chood))\n",
      "    \n",
      "    def find_postings(self):\n",
      "        pass\n",
      "    \n",
      "        \n",
      "postslash = lambda x: '' if x is None else x+'/'\n",
      "preslash = lambda x: '' if x is None else '/'+x\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 175
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ms = Search('seattle', 'mcy', query='sport', chood='see', csearchtype='A', minask=1, maxask='10000')\n",
      "site = ms.format_search_url()\n",
      "print site\n",
      "r = requests.get(site)\n",
      "soup = BeautifulSoup(r.text)   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://seattle.craigslist.org/search/mcy/see?query=sport&srchType=A&minAsk=1&maxAsk=10000&hasPic=0\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "postings = soup('p')\n",
      "\n",
      "for bs4tag in postings[:10]:  \n",
      "    post_href = bs4tag('a')[1].get('href')[1:]\n",
      "    post = Post('http://%s.craigslist.org/'%ms.ccity + post_href, Post.find_price(bs4tag))\n",
      "    post.parse_post_metadata()\n",
      "    print post.title\n",
      "    print post.price\n",
      "    print post.posted_time\n",
      "    print post.updated_time\n",
      "    print post.postid\n",
      "    print post.user_email\n",
      "    print post.url\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "96' KTM 620 RXC STREET LEGAL RACE BIKE\n",
        "2750\n",
        "2014-03-27T16:09:48-0700\n",
        "None\n",
        "4395330783\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4395330783.html\n",
        "\n",
        "90cc Blast! Quad, ATV - Plus Kids Protective Racing Pants for Sale!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500\n",
        "2014-03-22T12:06:08-0700\n",
        "2014-03-27T15:50:37-0700\n",
        "4387186766\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4387186766.html\n",
        "\n",
        "Yamaha Banshee, Quad, ATV, price reduction"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2500\n",
        "2014-03-22T12:10:01-0700\n",
        "2014-03-27T15:49:42-0700\n",
        "4387193279\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4387193279.html\n",
        "\n",
        "2008 YAMAHA R1 RAVEN EDITION (LOW MILES)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7\n",
        "2014-03-22T16:34:44-0700\n",
        "2014-03-27T15:53:25-0700\n",
        "4387584385\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4387584385.html\n",
        "\n",
        "1986 Honda XR 600R"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000\n",
        "2014-03-27T14:48:11-0700\n",
        "None\n",
        "4395212201\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4395212201.html\n",
        "\n",
        "2001 drz 400 Dual sport"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2200\n",
        "2014-03-27T10:54:12-0700\n",
        "None\n",
        "4394806454\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4394806454.html\n",
        "\n",
        ">> Super Clean << 2010 Kawasaki Z1000 ** Priced to Sell ** "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6895\n",
        "2014-03-25T09:13:12-0700\n",
        "2014-03-27T10:39:57-0700\n",
        "4391396988\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4391396988.html\n",
        "\n",
        " Harley softail Custom "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9550\n",
        "2014-03-27T09:16:31-0700\n",
        "None\n",
        "4394623615\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4394623615.html\n",
        "\n",
        "WTB: 50cc street bike / Derbi GPR 50, YSR 50, Aprilia 50 etc"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1100\n",
        "2014-03-13T15:47:33-0700\n",
        "2014-03-27T08:03:18-0700\n",
        "4373742420\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4373742420.html\n",
        "\n",
        "Suzuki DR200se Dualsport"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2200\n",
        "2014-03-21T20:13:41-0700\n",
        "2014-03-27T03:20:21-0700\n",
        "4386327437\n",
        "None\n",
        "http://seattle.craigslist.org/see/mcy/4386327437.html\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "post.postsoup.find('section', id='postingbody').text.strip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 192,
       "text": [
        "u'2004 Suzuki DR200se for sale. Perfect bike to learn on. Street legal. Current tabs and plate. Recently replaced seat and battery. Great dual sport for anyone interested in riding streets and trails. 2200 OBO. Any questions or want to make an offer just email me. Possibly interested in trading for a sport bike.'"
       ]
      }
     ],
     "prompt_number": 192
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scratch"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "html_doc = \"\"\"\n",
      "<html><head><title>The Dormouse's story</title></head>\n",
      "\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
      "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
      "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "\"\"\"\n",
      "soup = BeautifulSoup(html_doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    }
   ],
   "metadata": {}
  }
 ]
}