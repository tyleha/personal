{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import email as em\n",
    "\n",
    "from datetime import date, timedelta, datetime\n",
    "from time import mktime\n",
    "from email.utils import parsedate, parsedate_tz, mktime_tz\n",
    "from email.parser import HeaderParser\n",
    "\n",
    "from classes.gmail import GmailAccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "password = open(os.path.expanduser('~/.ssh/pw'), 'r').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('OK', [b'tyleha@gmail.com authenticated (Success)'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tyler = GmailAccount(username='tyleha@gmail.com', password=password)\n",
    "tyler.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daysback = 70\n",
    "notsince = 0\n",
    "since = (date.today() - timedelta(daysback)).strftime(\"%d-%b-%Y\")\n",
    "before = (date.today() - timedelta(notsince)).strftime(\"%d-%b-%Y\")\n",
    "\n",
    "SEARCH = '(SENTSINCE {si} SENTBEFORE {bf})'.format(si=since, bf=before)\n",
    "BODY = '(BODY.PEEK[TEXT])'\n",
    "ALL_HEADERS = '(BODY.PEEK[HEADER.FIELDS (DATE TO CC FROM SUBJECT)])'\n",
    "DATE = '(BODY.PEEK[HEADER.FIELDS (DATE)])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOAD GMAIL EMAILS\n",
    "received = tyler.load_parse_query(SEARCH, ALL_HEADERS, '\"[Gmail]/All Mail\"')\n",
    "# sent = tyler.load_parse_query(SEARCH, ALL_HEADERS, '\"[Gmail]/Sent Mail\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pickle(filepath, ftype='r'):\n",
    "    \"\"\"opens and closes pickled file and returns contained pickleobj\"\"\"\n",
    "    f = open(filepath, ftype)\n",
    "    contents = pickle.load(f)\n",
    "    f.close()\n",
    "    return contents    \n",
    "\n",
    "def save_pickle(content, filepath, ftype='w'):\n",
    "    \"\"\"\n",
    "    :return: pickle's weird dump output. not useful\n",
    "    :content: the object to be saved (can be any type)\n",
    "    :filepath: the string path, relative or not, at which to save\n",
    "    :ftype: 'w' to write, 'wb' to write binary\n",
    "    \"\"\"\n",
    "    f = open(filepath, ftype)\n",
    "    xx = pickle.dump(content, f)\n",
    "    f.close()\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the pandas thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrub_email(headers):    \n",
    "    d = {}\n",
    "    for val in headers:\n",
    "        d[val[0].lower()] = val[1]\n",
    "    return d\n",
    "\n",
    "def try_parse_date(d):\n",
    "    try:\n",
    "        ts = pd.Timestamp(d)\n",
    "\n",
    "        # IMAP is very much not perfect...some of my emails have no timezone\n",
    "        # in their date string. ¯\\_(ツ)_/¯\n",
    "        if ts.tz is None: \n",
    "            ts = ts.tz_localize('UTC')\n",
    "\n",
    "        # I moved from east coast to west coast in fall 2010, so automatically assume EST/PST \n",
    "        # before/after that date.\n",
    "        if ts < pd.Timestamp('2010-09-04', tz='US/Eastern'):\n",
    "            ts = ts.tz_convert('US/Eastern')\n",
    "        else:\n",
    "            ts = ts.tz_convert('US/Pacific')\n",
    "        # I would have liked to avoid this whole parse_date method altogether and instead just\n",
    "        # use pd.Timestamp(df.date), however Pandas is _really_ not built to handle DatetimeIndex\n",
    "        # or PeriodIndex of anything other than a single timezone (see http://stackoverflow.com/a/17027507/1766755)\n",
    "        # Because we care about timezone-naive datestamps and Pandas forces us to be timezone aware, \n",
    "        # we have to fall back to the datetime library and strip timezone from all our dates\n",
    "        # using tzinfo=None.\n",
    "        return pd.Timestamp(ts.to_datetime().replace(tzinfo=None))\n",
    "    \n",
    "    except:\n",
    "        # Sometimes, IMAP just has dates formatted in a totally improper \n",
    "        # way...see 'Thursday , 10 Dec 2009 16:28:55, PST'. These are so few and far between and so\n",
    "        # irregular that we'll just remove them from our dataset.\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "received = load_pickle('/home/tyleha/git/all_emails', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = 'M'\n",
    "email_dataset = received\n",
    "df = pd.DataFrame([scrub_email(email._headers) for email in email_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Frequency\n",
    "freq = 'M'\n",
    "email_dataset = sent\n",
    "df = pd.DataFrame([scrub_email(email._headers) for email in email_dataset])\n",
    " \n",
    "# This might take a minute...\n",
    "df['timestamp'] = df.date.map(try_parse_date)\n",
    "df = df.dropna(subset=['timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we're off to the races\n",
    "df['hour'] = df.timestamp.map(lambda x: x.hour)\n",
    "df = df.set_index('timestamp', drop=False)\n",
    "df.index = df.index.to_period(freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 of 4    [##################### 100% #####################]    Time: 0:00:00    ETA: ..."
     ]
    }
   ],
   "source": [
    "# Scale our heatmap to the min/max range of our email data.\n",
    "mindate = df.timestamp.min()\n",
    "maxdate = df.timestamp.max()\n",
    "pr = pd.period_range(mindate, maxdate, freq=freq)\n",
    "\n",
    "# Initialize a new HeatMap dataframe where the indicies are actually Periods of time!\n",
    "# Size the frame anticipating the correct number of rows (periods) and columns (hours in a day)\n",
    "hm = pd.DataFrame(np.zeros([len(pr), 24]) , index=pr)\n",
    "\n",
    "from classes.progress import ProgressBar\n",
    "\n",
    "prog = ProgressBar(len(pr))\n",
    "for i, period in enumerate(pr):\n",
    "    # HERE'S where the magic happens...with pandas, when you structure your data correctly, it can be so terse that\n",
    "    # you almost aren't sure the program does what it says it does...\n",
    "    # For this period (month), find all emails within this month and count how many emails were received\n",
    "    # within each hour of the day in that month. Wow. Takes more words to explain than to code.\n",
    "    # Normally that would take you 3 or 4 for loops, constantly trying to catch edge cases and fencepost\n",
    "    # problems. But here, it's as simple as you please.\n",
    "    if period in df.index:\n",
    "        hm.ix[period] = df.loc[[period]].hour.value_counts()\n",
    "    prog.animate(i)\n",
    "    \n",
    "# If for some weird reason there was ever an hour period where you had no email,\n",
    "# fill those NaNs with zeros.\n",
    "hm.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmap Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hide that time I sent a bajillion wedding save the date emails\n",
    "hm.ix[pd.Period('2013-04', 'M')][18] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "from datetime import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[4,1], width_ratios=[20,1],)\n",
    "gs.update(wspace=0.05)\n",
    "\n",
    "### Plot our heatmap\n",
    "ax = plt.subplot(gs[0])\n",
    "x = dates.date2num([p.start_time for p in pr])\n",
    "t = [datetime(2000, 1, 1, h, 0, 0) for h in range(24)]\n",
    "t.append(datetime(2000, 1, 2, 0, 0, 0))\n",
    "y = dates.date2num(t)\n",
    "cm = plt.get_cmap('Blues')\n",
    "plt.pcolor(x, y, hm.transpose().as_matrix(), cmap=cm)\n",
    "\n",
    "date_format = dates.DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_formatter(date_format)\n",
    "ax.yaxis.set_major_formatter(dates.DateFormatter('%H:%M'))\n",
    "ax.set_yticks(t[::2])\n",
    "ax.set_xticks(x[::12])\n",
    "# fig.autofmt_xdate()\n",
    "\n",
    "ax.set_xlim([x[0], x[-1]])\n",
    "ax.set_ylim([t[0], t[-1]])\n",
    "\n",
    "# Add a colorbar!\n",
    "plt.colorbar(cax=plt.subplot(gs[1]))\n",
    "\n",
    "#### Plot total emails over time \n",
    "ax2 = plt.subplot(gs[2])\n",
    "g = df.groupby(level=0)\n",
    "total_email = g.hour.count()\n",
    "plt.plot_date(total_email.index, total_email, '-', linewidth=1.5, color=cm(0.999))\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = plt.imshow(hm.transpose(), interpolation='nearest', cmap='Oranges').axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = parsedate_tz('Fri, 3 Sep 2010 21:26:05 -0500')\n",
    "x = parsedate_tz('Thu, 31 Dec 2015 02:07:11 +0000')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.Timestamp('Thu, 31 Dec 2015 02:07:11 +0000')\n",
    "y = y.tz_convert('US/Eastern')\n",
    "pd.Timestamp(y.to_datetime().replace(tzinfo=None)).tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Timestamp('Fri, 3 Sep 2010 21:26:05 -0500').to_datetime().replace(tzinfo=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
